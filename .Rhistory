X <- cbind(1, X) # add a column
y <- cars$dist
beta.mle <- solve(t(X) %*% X) %*% t(X) %*% y
beta.mle
X <- as.matrix(fuel2001[, -2])
abline(beta.mle)
data("cars")
f <- function(x) return (sin(x))
f.prime <- function(x) return (cos(X))
f.dprime <- function(x) return (-sin(x))
theta.range <- seq(-3*pi, pi, 5e2)
plot(theta.range, f(theta.range))
theta.range
theta.range <- seq(-3*pi, pi, length = 5e2)
plot(theta.range, f(theta.range))
plot(theta.range, f(theta.range), 'l')
while(err > tol){
count = count + 1
theta.hats[count] <- theta.hats[count -1] + f.prime(theta.hats[count -1])/f.dprime(theta.hats[count -1])
err <- f.prime(theta.hats[count -1])
}
theta.hats <- numeric()
theta.hats[1] <- -4
tol <- 1e-6
err <- 100
count <- 1
while(err > tol){
count = count + 1
theta.hats[count] <- theta.hats[count -1] + f.prime(theta.hats[count -1])/f.dprime(theta.hats[count -1])
err <- f.prime(theta.hats[count -1])
}
tol <- 1e-10
compare <- 100
iter <- 1
xk <- c() # will store sequence here
xk[1] <- .5 # starting value
while(compare > tol)
{
iter <- iter + 1 # tracking iterations
gradient <- f.prime(xk[iter - 1])
hessian <- f.dprime(xk[iter - 1])
xk[iter] <- xk[iter - 1] - gradient/hessian
compare <- abs(gradient)
}
compare
f <- function(x) return (sin(x))
f.prime <- function(x) return (cos(X))
f.dprime <- function(x) return (-sin(x))
theta.range <- seq(-3*pi, pi, length = 5e2)
plot(theta.range, f(theta.range), 'l')
tol <- 1e-10
compare <- 100
iter <- 1
xk <- c() # will store sequence here
xk[1] <- .5 # starting value
compare
tol
while(compare > tol)
{
iter <- iter + 1 # tracking iterations
gradient <- f.prime(xk[iter - 1])
hessian <- f.dprime(xk[iter - 1])
xk[iter] <- xk[iter - 1] - gradient/hessian
compare <- abs(gradient)
}
while(compare > tol)
{
iter <- iter + 1 # tracking iterations
gradient <- f.prime(xk[iter - 1])
hessian <- f.dprime(xk[iter - 1])
xk[iter] <- xk[iter - 1] - gradient/hessian
compare <- abs(gradient)
}
f <- function(x) return (sin(x))
f.prime <- function(x) return (cos(x))
f.dprime <- function(x) return (-sin(x))
theta.range <- seq(-3*pi, pi, length = 5e2)
plot(theta.range, f(theta.range), 'l')
tol <- 1e-10
compare <- 100
iter <- 1
xk <- c() # will store sequence here
xk[1] <- .5 # starting value
while(compare > tol)
{
iter <- iter + 1 # tracking iterations
gradient <- f.prime(xk[iter - 1])
hessian <- f.dprime(xk[iter - 1])
xk[iter] <- xk[iter - 1] - gradient/hessian
compare <- abs(gradient)
}
iter
points(xk, f(xk))
################################################
## MLE for location Cauchy distribution using
## Newton-Raphson method
## We will plot the likelihood as well
################################################
set.seed(1)
mu.star <- 5  # Setting true mu
n <- 4  # sample size
X <- rt(n, df = 1) + mu.star
## Function calculates  the log-likelihood
log.like <- function(mu, X)
{
n <- length(X)
rtn <- -n*log(pi) - sum( log(1 + (X - mu)^2) )
return(rtn)
}
mu.x <- seq(-10, 40, length = 1e3)  # A sequence of mu's
ll.est <- sapply(mu.x, log.like, X)  # evaluating log-likelihood at the mus
plot(mu.x, ll.est, type = 'l', ylab = "log-likelihood", xlab = expression(mu))  # plotting log-likelihood. Not concave, so we need to choose good starting values.
## Starting Newton-Raphson method
tol <- 1e-5  # tolerance level for when to stop algorithm
## Returns derivate of log-likelihood
f.prime <- function(X, mu)
{
rtn <- sum(2* (X - mu)/(1 + (X-mu)^2))  #f.prime
return(rtn)
}
# Returns double derivative of log-likelihood.
f.double.prime <- function(X, mu)
{
rtn <- sum( 2 * ( 2*(X-mu)^2/ (1 + (X - mu)^2)^2  - (1 + (X-mu)^2)^(-1) )  )
return(rtn)
}
## Loop below stops when |mu_(k+1) - mu_(k)| < tol
current <- median(X)  # Good starting value
diff <- 100  # inital large value for difference
iter <- 0    # counting the number of iterations
mu.k <- current
while( (diff > tol) && iter < 100)
{
iter <- iter + 1
update <- current - f.prime(X, current)/f.double.prime(X, current)  # NR update
mu.k <- c(mu.k, update)
diff <- abs(current - update)
current <- update
}
current  # final approximation to MLE
evals <- sapply(mu.k, log.like, X)
plot(mu.x, ll.est, type = 'l', ylab = "log-likelihood", xlab = expression(mu))
points(mu.k, evals, pch = 16, col = rgb(0,0,1, alpha = .5))
## Loop below stops when |mu_(k+1) - mu_(k)| < tol
current <- 7  # Bad starting value
diff <- 100
iter <- 0
mu.k <- current
while( (diff > tol) && iter < 100)
{
iter <- iter + 1
update <- current - f.prime(X, current)/f.double.prime(X, current)
mu.k <- c(mu.k, update)
diff <- abs(current - update)
current <- update
}
current  # final approximation to MLE
evals <- sapply(mu.k, log.like, X)
points(mu.k, evals, pch = 16, col = rgb(1,0,0, alpha = .5))
current <- 19  # Worst starting value
diff <- 100
iter <- 0
mu.k <- current
while( (diff > tol) && iter < 100)
{
iter <- iter + 1
update <- current - f.prime(X, current)/f.double.prime(X, current)
mu.k <- c(mu.k, update)
diff <- abs(current - update)
current <- update
}
current  # final approximation to MLE
evals <- sapply(mu.k, log.like, X)
points(mu.k, evals, pch = 16, col = rgb(.2,.7,.1, alpha = .8))
legend("topright", legend = c("Good starting", "Bad starting", "Horrible starting"), pch = 16, col = c("blue", "red", rgb(.2,.7,.1)))
titanic <- read.csv("https://dvats.github.io/assets/titanic.csv")
head(titanic)
titanic <- read.csv("https://dvats.github.io/assets/titanic.csv")
head(titanic)
Y <- titanic$Survived
f.gradient <- function(y, X, beta)
{
# converting beta to compatible matrix form
beta <- matrix(beta, ncol = 1)
pi.vec <- 1 / (1 + exp(-X%*%beta))
rtn <- colSums(X* as.numeric(y - pi.vec))
return(rtn)
}
f.hessian <- function(y, X, beta)
{
beta <- matrix(beta, ncol = 1)
W_i <- exp(X%*%beta) / (1 + exp(X%*%beta))^2
W <- diag(as.numeric(W_i))
rtn <- - t(X) %*% W %*% X
}
tol <- 1e-10
compare <- 100
iter <- 1
# starting from the zero-vector
grad.vec <- c() # will store gradients here
beta.current <- rep(0, p)
p <- dim(X)[2]
y <- titanic$Survived
X <- as.matrix(titanic[, -1]) # everything but the first column is the X
# will need these later
p <- dim(X)[2]
n <- length(y)
tol <- 1e-10
compare <- 100
iter <- 1
# starting from the zero-vector
grad.vec <- c() # will store gradients here
beta.current <- rep(0, p)
beta.new <- beta.current
while(compare > tol)
{
iter <- iter + 1 # tracking iterations
gradient <- f.gradient(y, X, beta.current)
hessian <- f.hessian(y, X, beta.current)
beta.new <- beta.current - qr.solve(hessian) %*% gradient
grad.vec[iter] <- norm(gradient, "2")
beta.current <- beta.new
compare <- grad.vec[iter]
}
iter
beta.new
# 1 for intercept, 1 for male,
jack.x <- c(1, 1, 20, 0, 0, 7.5)
rose.x <- c(1, 0, 19, 1, 1, 512)
# estimate from logistic reg is in beta.new
pi.jack <- 1/ (1 + exp( - sum(jack.x * beta.new)))
pi.rose <- 1/ (1 + exp( - sum(rose.x * beta.new)))
data.final <- read.csv("../Happiness_Suicides.csv")
data.final <- read.csv("../Happiness_Suicides.csv")
head(data.final)
View(data.final)
data.suicides <- read.csv("suicide_cleaned.csv")
head(data.suicides)
data.urban.bliss <- read.csv("- train US new.csv")
head(data.urban.bliss)
data.happiness <- read.csv("Happiness_cleaned.csv")
head(data.happiness)
continents <- unique(data.suicides$continent)
for(cont in continents){
dat <- data.suicides[which(data.suicides$continent == cont),]
gdps <- unique(dat$gdp_per_capita)
gdps <- sort(gdps)
suicides <- numeric(length = length(gdps))
counter <- 1
for(i in gdps){
suicides[counter] <- sum(dat$suicides.100k.pop[which(dat$gdp_per_capita == i)])
counter <- counter + 1
}
plot(gdps,suicides,'l', xlab = "GDP per capita", ylab = "No. of Suicides", main = paste("GDP vs. Suicide Rate for", cont))
}
dat.happy <- data.happiness[which(data.happiness$Continent == "Europe"),]
plot(dat.happy$Economy..GDP.per.Capita., dat.happy$Happiness.Score,
xlab = "GDP per Capita",
ylab = "Happiness Score",
main = "Europe")
abline(lm(dat.happy$Happiness.Score~dat.happy$Economy..GDP.per.Capita.),col = "red")
legend("bottomright", "Line of Best Fit", fill = "red")
continents <- unique(data.suicides$continent)
for(cont in continents){
dat.happy <- data.happiness[which(data.happiness$Continent == cont),]
plot(dat.happy$Economy..GDP.per.Capita., dat.happy$Happiness.Score,
xlab = "GDP per Capita",
ylab = "Happiness Score",
main = cont)
abline(lm(dat.happy$Happiness.Score~dat.happy$Economy..GDP.per.Capita.),col = "red")
legend("bottomright", "Line of Best Fit", fill = "red")
}
dat.happy <- data.happiness[which(data.happiness$Continent == "Europe"),]
plot(dat.happy$Economy..GDP.per.Capita., dat.happy$Health..Life.Expectancy.,
xlab = "GDP per Capita",
ylab = "Health Index",
main = "Europe")
abline(lm(dat.happy$Health..Life.Expectancy.~dat.happy$Economy..GDP.per.Capita.),col = "red")
legend("bottomright", "Line of Best Fit", fill = "red")
cor(dat.happy$Health..Life.Expectancy.,fitted(lm(dat.happy$Health..Life.Expectancy.~dat.happy$Economy..GDP.per.Capita.))) # multiple correlation
Continents <- unique(data.suicides$continent)
corr.values <- data.frame(Continents)
values <- numeric(length = length(Continents))
counter = 1
for(cont in continents){
dat.happy <- data.happiness[which(data.happiness$Continent == cont),]
values[counter] <- (cor(dat.happy$Health..Life.Expectancy.,fitted(lm(dat.happy$Health..Life.Expectancy.~dat.happy$Economy..GDP.per.Capita.)))
)
counter <- counter + 1
}
corr.values$`Corr Values`<-values
corr.values
boxplot(Happiness.Score ~ Continent, data = data.happiness, col = 'coral')
View(data.suicides)
unique(data.suicides$age)
sort(unique(data.suicides$age))
boxplot(data.suicides$suicides_no~data.suicides$age)
boxplot(data.suicides$suicides.100k.pop~data.suicides$age)
plot(density(data.suicides$suicides.100k.pop~data.suicides$age))
plot(density(data.suicides$suicides.100k.pop))
dat <- data.suicides$suicides_no[data.suicides$age = "15-24 years"]
dat <- data.suicides$suicides_no[data.suicides$age = "15-24 years"]
dat <- data.suicides$suicides_no[data.suicides$age == "15-24 years"]
plot(density(dat))
for(year in unique(data.suicides$age)){
dat <- data.suicides$suicides_no[data.suicides$age == year]
plot(density(dat))
}
for(year in unique(data.suicides$age)){
dat <- data.suicides$suicides.100k.pop[data.suicides$age == year]
plot(density(dat))
}
for(year in unique(data.suicides$age)){
dat <- data.suicides$suicides.100k.pop[data.suicides$age == year]
plot(density(dat), main = year, xlab = "Suicides per 100k people")
}
upper <- c("Europe", "North America", "Asia", "Europe; Asia")
top.happiness <- data.happiness[data.happiness$Continent %in% upper,]
bot.happiness <- data.happiness[!data.happiness$Continent %in% upper,]
top.score <- top.happiness$Happiness.Score
bot.score <- bot.happiness$Happiness.Score
m.top <- mean(top.score)
m.bot <- mean(bot.score)
n1 <- length(top.score)
n2 <- length(bot.score)
m <- m.top - m.bot
s <- sqrt(1/n1 + 1/n2) * sqrt((sum((top.score - m.top)^2) + sum((bot.score - m.bot)^2))/(n1 + n2 - 2))
paste0("Difference is m : ", m)
paste0("Deviation : ", s)
# Hypothesis : Mean of Upper Hemisphere <= Mean of Bottom Hemisphere
p.zero <- pnorm(-m/s)
paste0("P value : ", p.zero)
means.age.groups <- data.frame(`Age Groups` = unique(data.suicides$age))
means <- numeric()
sds <- numeric()
counter <- 1
for(year in unique(data.suicides$age)){
dat <- data.suicides$suicides.100k.pop[data.suicides$age == year]
plot(density(dat), main = year, xlab = "Suicides per 100k people")
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
counter <- counter + 1
}
means.age.groups$`Mean Value` <- means
means.age.groups$`Standard Deviation` <- sds
means.age.groups
means.age.groups <- data.frame(`Age Groups` = unique(data.suicides$age))
means <- numeric()
sds <- numeric()
counter <- 1
for(year in unique(data.suicides$age)){
dat <- data.suicides$suicides.100k.pop[data.suicides$age == year]
plot(density(dat), main = year, xlab = "Suicides per 100k people")
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
counter <- counter + 1
}
means.age.groups$`Mean Value` <- means
means.age.groups$`Standard Deviation` <- sds
View(dat.happy)
View(data.urban.bliss)
means.age.groups
generations <- data.frame(unique(data.suicides$generation))
generations
generations <- data.frame(Generation = unique(data.suicides$generation))
generations
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
counter <- 1
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$suicides.100k.pop[data.suicides$generation = gen]
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
counter <- 1
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$suicides.100k.pop[data.suicides$generation == gen]
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
counter <- counter + 1
}
generations$Mean <- means
generations$`Standard Deviation` <- sds
generations
dat.1 <- data.happiness$Happiness.Score[data.happiness$Year < 2018]
dat.2 <- data.happiness$Happiness.Score[data.happiness$Year >= 2018]
mean(dat.1),mean(dat.2)
dat.1 <- data.happiness$Happiness.Score[data.happiness$Year < 2018]
dat.2 <- data.happiness$Happiness.Score[data.happiness$Year >= 2018]
mean(dat.1);mean(dat.2)
lm(dat.happy$Happiness.Score~data.happiness$Economy..GDP.per.Capita.)
View(dat.happy)
lm(dat.happy$Happiness.Score~data.happy$Economy..GDP.per.Capita.)
lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.)
coefficients(lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.))
coeff <- coefficients(lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.))
coeff
coeff[1]
coeff[2]
coeff[2] + 9
9 + coeff[2]
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
counter <- 1
coeff <- coefficients(lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.))
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$gdp_per_capita[data.suicides$generation == gen]
dat <- coeff[1] + coeff[2]*dat
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
counter <- counter + 1
}
generations$Mean <- means
generations$`Standard Deviation` <- sds
generations
coeff
as.numeric(coeff)
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
counter <- 1
coeff <- coefficients(lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.))
coeff <- as.numeric(coeff)
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$gdp_per_capita[data.suicides$generation == gen]
dat <- dat / 1e3
dat <- coeff[1] + coeff[2]*dat
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
counter <- counter + 1
}
generations$`Mean ` <- means
generations$`Standard Deviation` <- sds
generations
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
counter <- 1
coeff <- coefficients(lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.))
coeff <- as.numeric(coeff)
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$gdp_per_capita[data.suicides$generation == gen]
dat <- dat / 1e4
dat <- coeff[1] + coeff[2]*dat
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
counter <- counter + 1
}
generations$`Mean ` <- means
generations$`Standard Deviation` <- sds
generations
continents <- unique(data.suicides$continent)
for(cont in continents){
dat <- data.suicides[which(data.suicides$continent == cont),]
gdps <- unique(dat$gdp_per_capita)
gdps <- sort(gdps)
suicides <- numeric(length = length(gdps))
counter <- 1
par(mfrow = c(2,4))
for(i in gdps){
suicides[counter] <- sum(dat$suicides.100k.pop[which(dat$gdp_per_capita == i)])
counter <- counter + 1
}
plot(gdps,suicides,'l', xlab = "GDP per capita", ylab = "No. of Suicides", main = paste("GDP vs. Suicide Rate for", cont))
}
library(e1071)
library(e1071)
#reading data
happiness <- read.csv("./Zehaan/Happiness_cleaned.csv")
setwd("~/209Project")
#reading data
happiness <- read.csv("./Zehaan/Happiness_cleaned.csv")
#train-test split
smp_size <- floor(0.75 * nrow(happiness))
set.seed(123)
train_ind <- sample(seq_len(nrow(happiness)), size = smp_size)
train <- happiness[train_ind, ]
test <- happiness[-train_ind, ]
#training model without PCA
model <- svm(Happiness.Score ~ . , data = train[,c(5,6,7)])
pred <- predict(model , test[,c(6,7)])
df <- data.frame ("pred" = pred , "true" = test[,5])
MAPE <- function(df){
foo <- abs(df[,2]-df[,1])
foo <- foo/df[,2]
val <- (sum(foo)/nrow(df))*100
return(val)
}
MSE <- function(df){
foo <- (df[,2]-df[,1])^2
return(sum(foo)/nrow(df))
}
Model_metrics <- c(MAPE(df),MSE(df))
happiness2 <- happiness[,c(5,6,7)]
pcs <- prcomp(happiness2[,c(2,3)])
data <- pcs$x
smp_size <- floor(0.75 * nrow(data))
#split
set.seed(123)
dat <- cbind(data , happiness2$Happiness.Score)
train_ind <- sample(seq_len(nrow(dat)), size = smp_size)
train <- dat[train_ind, ]
test <- dat[-train_ind, ]
#SVM
model2 <- svm(x = train[,c(1,2)] , y = train[,3])
pred2 <- predict(model2 , test[,c(1,2)])
df2 <- data.frame ("pred" = pred2 , "true" = test[,3])
Model2_metrics <- c(MAPE(df2),MSE(df2))
upper <- c("Europe", "North America", "Asia", "Europe; Asia")
top.happiness <- data.happiness[data.happiness$Continent %in% upper,]
